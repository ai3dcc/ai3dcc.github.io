<!Doctype html>
<html lang="en">
    <head>
        <title>AI3DCC: Workshop on AI for 3D Content Creation</title>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="author" content="Despoina Paschalidou">
        <meta name="description" content="Workshop page for ai3dcc">
        <!-- Bootstrap -->
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
        <link rel="stylesheet" type="text/css" href="style.css?cache=77333914184988801948">
        <link rel="icon" type="image/png" href="figures/favicon.png"/>
    </head>
    <body>
        <div id="navbar-top">
        <nav class="navbar navbar-light px-3">
            <a class="navbar-brand" href="https://iccv2023.thecvf.com/">AI3DCC @ ICCV2023</a>
            <ul class="nav nav-pills">
              <li class="nav-item">
                <a class="nav-link active" href="#home">Home</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#submission">Submission</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#schedule">Schedule</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#speakers">Speakers</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#">Program Committee</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#organizers">Organizers</a>
              </li>
            </ul>
        </nav>
        </div>
        <div data-bs-spy="scroll" data-bs-target="#navbar-example2" data-bs-offset="0" class="scrollspy-example" tabindex="0">
        <div class="jumbotron" id="home">
            <div class="title">
                <h4>The first workshop on</h4>
                <h2>AI for 3D Content Creation</h2>
                <h4>October @ ICCV 2023 Paris, France</h4>
            </div>

            <div id="carouselExampleDark" class="carousel carousel-dark slide" data-bs-ride="carousel">
                  <div class="carousel-indicators">
                    <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="0" class="active" aria-current="true" aria-label="Slide 1"></button>
                    <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="1" aria-label="Slide 2"></button>
                    <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="2" aria-label="Slide 3"></button>
                    <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="3" aria-label="Slide 4"></button>
                    <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="4" aria-label="Slide 5"></button>
                    <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="5" aria-label="Slide 6"></button>
                    <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="6" aria-label="Slide 7"></button>
                    <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="7" aria-label="Slide 8"></button>
                  </div>
                  <div class="carousel-inner">
                    <div class="carousel-item" data-bs-interval="2000">
                      <video autoplay muted loop height="500">
                        <source src="gfx/carousel/dreamfusion.mp4" type="video/mp4">
                      </video>
                      <div class="carousel-caption d-none d-md-block">
                        <h5>DreamFusion: Text-to-3D using 2D Diffusion</h5>
                        <p>ICLR 2023</p>
                      </div>
                    </div>
                    <div class="carousel-item" data-bs-interval="2000">
                      <video autoplay muted loop height="500">
                        <source src="gfx/carousel/magic3d.mp4" type="video/mp4">
                      </video>
                      <div class="carousel-caption d-none d-md-block">
                        <h5>Magic3D: High-Resolution Text-to-3D Content Creation</h5>
                        <p>CVPR 2023</p>
                      </div>
                    </div>
                    <div class="carousel-item" data-bs-interval="2000">
                      <video autoplay muted loop height="500">
                        <source src="gfx/carousel/get3d.mp4" type="video/mp4">
                      </video>
                      <div class="carousel-caption d-none d-md-block">
                        <h5>GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images</h5>
                        <p>NeurIPS 2022</p>
                      </div>
                    </div>
                    <div class="carousel-item" data-bs-interval="2000">
                      <video autoplay muted loop height="500">
                        <source src="gfx/carousel/lion.mp4" type="video/mp4">
                      </video>
                      <div class="carousel-caption d-none d-md-block">
                        <h5>LION: Latent Point Diffusion Models for 3D Shape Generation</h5>
                        <p>NeurIPS 2022</p>
                      </div>
                    </div>
                    <div class="carousel-item" data-bs-interval="2000">
                      <video autoplay muted loop height="500">
                        <source src="gfx/carousel/instruct-nerf2nerf.mp4" type="video/mp4">
                      </video>
                      <div class="carousel-caption d-none d-md-block">
                        <h5>Instruct-NeRF2NeRF Editing 3D Scenes with Instructions</h5>
                        <p>arxiv 2023</p>
                      </div>
                    </div>
                    <div class="carousel-item active" data-bs-interval="2000">
                      <video autoplay muted loop height="500">
                        <source src="gfx/carousel/atiss_synthesis.webm" type="video/webm">
                      </video>
                      <div class="carousel-caption d-none d-md-block">
                        <h5>ATISS: Autoregressive Transformers for Indoor Scene Synthesis</h5>
                        <p>NeurIPS 2021</p>
                      </div>
                    </div>
                    <div class="carousel-item">
                      <video autoplay muted loop height="500">
                        <source src="gfx/carousel/infinite-nature.mp4" type="video/mp4">
                      </video>
                      <div class="carousel-caption d-none d-md-block">
                        <h5>InfiniteNature-Zero Learning Perpetual View Generation of Natural Scenes from Single Images</h5>
                        <p>ECCV 2022</p>
                      </div>
                    </div>
                    <div class="carousel-item">
                      <video autoplay muted loop height="500">
                        <source src="gfx/carousel/trace_and_pace.mp4" type="video/mp4">
                      </video>
                      <div class="carousel-caption d-none d-md-block">
                        <h5>Trace and Pace: Controllable Pedestrian Animation
                            via Guided Trajectory Diffusion</h5>
                        <p>CVPR 2023</p>
                      </div>
                    </div>
                  </div>
                  <button class="carousel-control-prev" type="button" data-bs-target="#carouselExampleDark" data-bs-slide="prev">
                    <span class="carousel-control-prev-icon" aria-hidden="true"></span>
                    <span class="visually-hidden">Previous</span>
                  </button>
                  <button class="carousel-control-next" type="button" data-bs-target="#carouselExampleDark" data-bs-slide="next">
                    <span class="carousel-control-next-icon" aria-hidden="true"></span>
                    <span class="visually-hidden">Next</span>
                  </button>
                </div>

            <div class="content"><div class="row"><div class="col">
            <p>
            Developing algorithms capable of generating realistic, high
            quality 3D data at scale has been a long standing problem in
            Computer Vision and Graphics. We anticipate that having generative
            models that can reliably synthesize meaningful 3D content will
            completely revolutionize the workflow of artists and content
            creators, and will also enable new levels of creativity through
            ``generative art". Although recently there has been considerable
            success in generating photorealistic images, the quality and
            generality of 3D generative models has lagged behind
            their 2D counterparts. Additionally, efficiently controlling what
            needs to be generated and scaling these approaches to complex
            scenes with several static and dynamic objects still remains an
            open challenge.
            </p>
            <p>
            In this workshop, we seek to bring together researchers working on generative
            models for 3D shapes, humans, and scenes to discuss the latest
            advances, existing limitations and next steps towards developing
            generative pipelines capable of producing fully controllable 3D
            environments with multiple humans interacting with each other or
            with objects in the scene. In the last few years, there has been
            significant progress in generating 3D objects, humans, and scenes
            independently, but only recently has the research community shifted
            their attention towards generating meaningful dynamics and
            interactions between humans or humans and other scene elements. To
            this end, in our workshop we look forward to cover the following
            topics:
            <ul>
                <li>What is the best representation for generating meaningful
            variations of 3D objects with texture and high quality details?</li>
                <li> What is the best representation to enable intuitive control over the generated
            objects? </li>
                <li> How to synthesize realistic humans performing plausible
            actions? </li>
                <li> How to generate fully controllable 3D environments, where it
            would be possible to manipulate both the appearance of the scene elements as
            well as their spatial composition? </li>
                <li> What is the best representation for
            generating plausible dynamics and interactions between humans or humans and
            objects? </li>
                <li> What are the ethical implications that arise from
            artificially generated 3D content and how we can address them. </li>
            </ul>
            </p>
            </div></div></div>
        </div>
        <div class="section">
        <div class="title">
            <span>News</span>
        </div>
            <div class="content"><div class="row"><div class="col">
                <ul>
                    <li><strong>April 3, 2024: </strong>
                    Workshop website launched, with the tentative list of the
                    invited speakers announced.</li>
                </ul>
            </div></div></div>
        </div>
        <div class="section" id="submission">
            <div class="title">
                <span>Call for Papers</span>
            </div>
            <div class="content"><div class="row"><div class="col">
            <p>We accept both archival and non-archival paper submissions. The
            accepted archival papers will be included in the ICCV2023 conference
            proceedings, while the non-archival will only be presented in the
            workshop. We welcome papers that are already accepted to the ICCV main
            conference or other previous conferences. These works will be included
            in the non-archival paper track. Every accepted paper will have the
            opportunity to host a poster presentation at the workshop.</p>

            We accept two forms of papers:
            <ul>
                <li><strong>Long paper:</strong> Long papers should not exceed 8
                pages excluding references and should use the
                <u><a href=https://iccv2023.thecvf.com/iccv2023authorkit-38--NQ.php> official ICCV
                template</a></u>. Long papers are for presenting mature works. A long paper
                should not only describe novel ideas but also include though experimental evaluation
                that supports the proposed ideas.
                </li>
                <li><strong>Short paper:</strong> Short papers should not exceed 4
                pages excluding references and should use the <u><a href=https://iccv2023.thecvf.com/iccv2023authorkit-38--NQ.php>
                official ICCV template</a></u>. Short papers are intended for presenting early stage
                ideas. Although comprehensive analyses and experiments are not
                necessary for short papers, they should have some basic experiments
                to support their claims. Moreover, in the short paper track, we
                <strong>encourage submissions focusing on creative contributions
                demonstrating applications of existing technology into 3D content
                creation pipelines</strong>. For example, we look forward for submissions
                showcasing how ongoing research on 3D generative AI can be
                used to facilitate the workflow of various fields such as
                architectural engineering, product designing, education, art,
                entertainment etc.</li>
            </ul>

            <p>All submissions should anonymized. Papers with more than 4 pages
            (excluding references) will be reviewed as long papers, and papers with
            more than 8 pages (excluding references) will be rejected without
            review. Supplementary material is optional with supported formats: pdf, mp4 and zip.
            All papers that were not previously presented in a major conference,
            will be peer-reviewed by three experts in the
            field in a double-blind manner. In case you are submitting a 
            previously accepted conference paper, please also attach a copy of the
            acceptance notification email in the supplementary material documents.</p>

            <p><strong>Submission Website:</strong> TBD</p>
            <p><strong>All submissions should follow the ICCV paper format:</strong>
                <a href=https://iccv2023.thecvf.com/iccv2023authorkit-38--NQ.php>https://iccv2023.thecvf.com/iccv2023authorkit-38--NQ.php</a></p>
            <p><strong>Paper Review Timeline:</strong>
            <table class="table">
                <tr>
                  <th scope="col">Paper Submission and supplemental material deadline</th>
                  <td> Monday, July 17, 2023 (AoE time)</td>
                </tr>
                <tr>
                  <th scope="col">Notification to authors</th>
                  <td>Friday, August 4, 2023 </td>
                </tr>
                <tr>
                  <th scope="col">Camera ready deadline</th>
                  <td>Friday, August 11, 2023 </td>
                </tr>
            </table>
            </p>
            </div></div></div>
        </div>

        <div class="section" id="speakers">
            <div class="title">
                <span>Keynote Speakers</span>
            </div>
            <div class="row">
                <div class="col-xs-6 col-md-3">
                    <div>
                        <a href="https://www.cs.utoronto.ca/~fidler/index.html" class="thumbnail">
                            <img src="gfx/speakers/sanja_fidler.jpg" alt="Sanja Fidler">
                            <div class="caption">
                                Sanja Fidler<br>
                                <span>University of Toronto and NVIDIA Research</span>
                            </div>
                        </a>
                    </div>
                </div>
                <div class="col-xs-6 col-md-3">
                    <a href="https://people.eecs.berkeley.edu/~kanazawa/" class="thumbnail">
                        <img src="gfx/speakers/angjoo_kanazawa.png" alt="Angjoo Kanazawa">
                        <div class="caption">
                            Angjoo Kanazawa<br><span>UC Berkeley</span>
                        </div>
                    </a>
                </div>
                <div class="col-xs-6 col-md-3">
                    <a href="https://jiajunwu.com/" class="thumbnail">
                        <img src="gfx/speakers/jiajun_wu.jpg" alt="Jiajun Wu">
                        <div class="caption">
                            Jiajun Wu<br><span>Stanford</span>
                        </div>
                    </a>
                </div>
                <div class="col-xs-6 col-md-3">
                    <a href="https://dritchie.github.io/" class="thumbnail">
                        <img src="gfx/speakers/daniel_ritchie.jpg" alt="Daniel Ritchie">
                        <div class="caption">
                            Daniel Ritchie<br><span>Brown University</span>
                        </div>
                    </a>
                </div>
            </div>
            <div class="row">
                <div class="col-xs-6 col-md-3 offset-md-3">
                    <a href="https://cs.stanford.edu/~poole/" class="thumbnail">
                        <img src="gfx/speakers/ben_poole.png" alt="Ben Poole">
                        <div class="caption">
                            Ben Poole<br><span>Google Brain</span>
                        </div>
                    </a>
                </div>
                <div class="col-xs-6 col-md-3">
                    <a href="https://sensilab.monash.edu/people/jon-mccormack/" class="thumbnail">
                        <img src="gfx/speakers/jon_mccormack.jpg" alt="Jon McCormack">
                        <div class="caption">
                            Jon McCormack<br><span>Monash University</span>
                        </div>
                    </a>
                </div>
            </div>
        </div>

        <div class="section">
            <div class="title">
                <span>Spotlight Speakers</span>
            </div>
            <div class="row">
                <div class="col-xs-6 col-md-3">
                    <a href="https://meshcapade.com/" class="thumbnail">
                        <img src="gfx/spotlight/naureen_mahmood.png" alt="Naureen Mahmood">
                        <div class="caption">
                            Naureen Mahmood<br><span>CEO of Meshcapade</span>
                        </div>
                    </a>
                </div>
                <div class="col-xs-6 col-md-3">
                    <a href="https://www.prometheanai.com/" class="thumbnail">
                        <img src="gfx/spotlight/andrew_maximov.jpg" alt="Andrew Maximov">
                        <div class="caption">
                            Andrew Maximov<br><span>CEO of Promethean AI</span>
                        </div>
                    </a>
                </div>
                <div class="col-xs-6 col-md-3">
                    <a href="https://tdevries.github.io/" class="thumbnail">
                        <img src="gfx/spotlight/terrance_devries.jpg" alt="Terrance DeVries">
                        <div class="caption">
                            Terrance DeVries<br><span>Cofounder of LumaAI</span>
                        </div>
                    </a>
                </div>
                <div class="col-xs-6 col-md-3">
                    <a href="https://https://kaihungchang.com/" class="thumbnail">
                        <img src="gfx/spotlight/kai_hung.jpg" alt="Kai-Hung Chang">
                        <div class="caption">
                            Kai-Hung Chang<br><span>ML Engineer at Google</span>
                        </div>
                    </a>
                </div>
            </div>
            <div class="row">
                <div class="col-xs-6 col-md-3 offset-md-4">
                    <a href="https:///https://mattdeitke.com/" class="thumbnail">
                        <img src="gfx/spotlight/matt-deitke.jpg" alt="Matt Deitke">
                        <div class="caption">
                            Matt Deitke<br><span>Researcher at Allen Institure for AI </span>
                        </div>
                    </a>
                </div>
            </div>
        </div>

        <div class="section" id="organizers">
            <div class="title">
                <span>Organizers</span>
            </div>
            <div class="row">
                <div class="col-xs-6 col-md-3">
                    <a href="https://paschalidoud.github.io/" class="thumbnail">
                        <img src="gfx/organizers/despoina_paschalidou_r.jpg" alt="Despoina Paschalidou">
                        <div class="caption">
                            Despoina Paschalidou<br><span>Stanford</span>
                        </div>
                    </a>
                </div>
                <div class="col-xs-6 col-md-3">
                    <a href="https://geopavlakos.github.io/" class="thumbnail">
                        <img src="gfx/organizers/georgios_pavlakos.jpg" alt="Georgios Pavlakos" class="top-left">
                        <div class="caption">
                            Georgios Pavlakos<br><span>UC Berkeley</span>
                        </div>
                    </a>
                </div>
                <div class="col-xs-6 col-md-3">
                    <a href="https://amlankar.github.io/" class="thumbnail">
                        <img src="gfx/organizers/amlan_kar.jpg" alt="Amlan Kar">
                        <div class="caption">
                            Amlan Kar<br><span>University of Toronto and NVIDIA Research</span>
                        </div>
                    </a>
                </div>
                <div class="col-xs-6 col-md-3">
                    <a href="https://kaichun-mo.github.io/" class="thumbnail">
                        <img src="gfx/organizers/kaichun_mo.jpg" alt="Kaihcun Mo">
                        <div class="caption">
                            Kaichun Mo<br><span>NVIDIA Research</span>
                        </div>
                    </a>
                </div>
            </div>
            <div class="row">
                <div class="col-xs-6 col-md-3">
                    <a href="https://davrempe.github.io/" class="thumbnail">
                        <img src="gfx/organizers/davis_rempe.jpg" alt="Davis Rempe" class="top-left">
                        <div class="caption">
                            Davis Rempe<br><span>NVIDIA Research</span>
                        </div>
                    </a>
                </div>
                <div class="col-xs-6 col-md-3">
                    <a href="https://paulguerrero.net/" class="thumbnail">
                        <img src="gfx/organizers/paul_guerrero.png" alt="Paul Guerrero">
                        <div class="caption">
                            Paul Guerrero<br><span>Adobe Research</span>
                        </div>
                    </a>
                </div>
                <div class="col-xs-6 col-md-3">
                    <a href="https://vlg.inf.ethz.ch/" class="thumbnail">
                        <img src="gfx/organizers/siyu_tang.jpg" alt="Siyu Tang">
                        <div class="caption">
                            Siyu Tang<br><span>ETH Zurich</span>
                        </div>
                    </a>
                </div>
                <div class="col-xs-6 col-md-3">
                    <a href="https://geometry.stanford.edu/member/guibas/" class="thumbnail">
                        <img src="gfx/organizers/leonidas_guibas.jpg" alt="Leonidas Guibas" class="top-left">
                        <div class="caption">
                            Leonidas Guibas<br><span>Stanford</span>
                        </div>
                    </a>
                </div>
            </div>
        </div>

        <div class="section">
            <div class="title">
                <span>Relevant Previous Workshops</span>
            </div>
            <div class="content">
                <ul>
                    <li>CVPR 2023: <a href="https://ai4cc.net/">AI for Content Creation</a> </li>
                    <li>CVPR 2022: <a href="https://ai4cc.net/2022/">AI for Content Creation</a> </li>
                    <li>ECCV 2022: <a href="https://learn3dg.github.io/">Learning to Generate 3D Shapes and Scenes</a> </li>
                    <li>CVPR 2021: <a href="https://ai4cc.net/2021/">AI for Content Creation</a> </li>
                    <li>CVPR 2021: <a href="https://learn3dg.github.io/static/2021.html">Learning to Generate 3D Shapes and Scenes</a> </li>
                    <li>CVPR 2020: <a href="https://ai4cc.net/2020/">AI for Content Creation</a> </li>
                    <li>CVPR 2020: <a href="https://learn3dgen.github.io/">Learning 3D Generative Models</a> </li>
                    <li>CVPR 2019: <a href="Deep Learning for Content Creation Tutorial">Deep Learning for Content Creation</a> </li>
                    <li>CVPR 2019: <a href="https://3dscenegen.github.io/">3D Scene Generation</a> </li>
                </ul>
            </div>
        </div>

        <div class="d-grid gap-2 d-md-flex justify-content-md-end">
            <a class="btn btn-primary me-md-2" role="button" href="#home" >Top</a>
        </div>

        <script>
            var scrollSpy = new bootstrap.ScrollSpy(document.body, {
                target: '#navbar-top'
            });
        </script>
        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-4LXC9BQBBX"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
        
          gtag('config', 'G-4LXC9BQBBX');
        </script>
    </body>
</html>
